<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing on DiTs"/>
  <meta property="og:description" content="DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing on DiTs"/>
  <meta property="og:url" content="https://dfvedit.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/framework.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DFVEdit</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/comic-mono@0.0.1/index.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
	    tex2jax: {
	        inlineMath: [['$','$'], ['\\(','\\)']],
	        processEscapes: true
	    }
	});
    </script>

  <script src="static/js/index.js"></script>
  
</head>
<body>

  <!-- FreeMask: Rethinking the Importance of Attention Masks \\ for Zero-Shot Video Editing -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="xtitle is-1 publication-title">
            <span style="font-weight: 1000;color: rgb(253, 187, 235)">DFVEdit:</span>
            <span>C</span>onditional  <span>D</span>elta  
            <span>F</span>low 
            <span>V</span>ector for
            <span>Zero-shot</span>  <span>V</span>ideo 
            <span>Edit</span>ing</span></h1>
          <div class="is-size-5 publication-authors">
              Submission Paper
          </div>
        </br>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block">
              <!-- <a href="https://chenyangqiqi.github.io/" target="_blank">Chenyang Qi</a><sup>1</sup></span>
              <span class="author-block"> -->
                <a target="_blank">Lingling Cai</a><sup>1</sup></span>
                <span class="author-block">
                  <a href="https://kangzhao2.github.io/" target="_blank">Kang Zhao</a><sup>2</sup>
                </span>
                <span class="author-block">
                  <a href="https://jacobyuan7.github.io/" target="_blank">Hangjie Yuan</a><sup>1,3</sup>
                </span>

                <span class="author-block">
                  <a href="https://jacobyuan7.github.io/" target="_blank">Xiang Wang</a><sup>2,4</sup>
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=16RDSEUAAAAJ&hl=zh-CN" target="_blank">Yingya Zhang</a><sup>2</sup>
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?hl=zh-CN&user=6tSoD98AAAAJ" target="_blank">Kejie Huang</a><sup>1</sup>
                </span>

                </div>
              
            </br>
                <div class="is-size-5 publication-authors">
                  <span class="author-block">
                  <sup>1</sup> Zhejiang University &nbsp;&nbsp;&nbsp;
                  <sup>2</sup> Tongyi Lab &nbsp;&nbsp;&nbsp;
                  <sup>3</sup> DAMO Academy &nbsp;&nbsp;&nbsp;
                  <sup>4</sup> Huazhong University of Science and Technology &nbsp;&nbsp;&nbsp;
                  <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span> -->
                </div>

                <div class="column has-text-centered">
                  <div class="publication-links">
                    
                     <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2409.20500" target="_blank"
                  class="external-link">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/LinglingCai0314/DFVEdit" target="_blank"
                  class="external-link ">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- Github link -->
              <span class="link-block">
                <a href="static/videos/DFVEdit.mp4" target="_blank"
                class="external-link ">
                <span class="icon">
                  <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>






<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-2">Method Overview</h2>
        <div class="content has-text-justified">
          <img src="static/images/framework.jpg"  width="100%" height="500px" />
        </div>
        <p class="content has-text-justified">
         <b>Abstract</b>: The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in video generation. However, directly applying existing video editing methods to Video DiTs often incurs substantial computational overhead, due to resource-intensive attention modification or finetuning. To alleviate this problem, we present DFVEdit, an efficient zero-shot video editing method tailored for Video DiTs. DFVEdit eliminates the need for both attention modification and fine-tuning by directly operating on clean latents via flow transformation. To be more specific, we observe that editing and sampling can be unified under the continuous flow perspective. Building upon this foundation, we propose the Conditional Delta Flow Vector (CDFV) -- a theoretically unbiased estimation of DFV -- and integrate Implicit Cross Attention (ICA) guidance as well as Embedding Reinforcement (ER) to further enhance editing quality. DFVEdit excels in practical efficiency, offering at least 20x inference speed-up and 85\% memory reduction on Video DiTs compared to attention-engineering-based editing methods. Extensive quantitative and qualitative experiments demonstrate that DFVEdit can be seamlessly applied to popular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art performance on structural fidelity, spatial-temporal consistency, and editing quality.
        </p>
      </div>
    </div>
  </div>
</section>


<!-- <section class="section hero">
  <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="column">
              <h2 class="title is-2">Method Overview</h2>
              <div class="content has-text-justified">
                  <embed src="static/images/frame0809.pdf" type="application/pdf" width="100%" height="500px" />
              </div>
              <p class="content has-text-justified">
                  <b>Left, Pipeline</b>: we store all the attention maps in the DDIM inversion pipeline.
                  At the editing stage of the DDIM denoising, we then fuse the attention maps with the stored attention maps using the proposed Attention Blending Block. 
                  <br/><br/><b>Right, Attention Blending Block</b>: First, we replace the cross-attention maps of un-edited words~(e.g., road and countryside) with their maps using the source prompt during inversion. As for the edited words (e.g., posche car), we blend the self-attention maps during inversion and editing with an adaptive spatial mask obtained from cross-attention, which represents the areas that the user wants to edit. 
              </p>
          </div>
      </div>
  </div>
</section> -->
<!-- End paper abstract -->

<!-- <section class="section hero ">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Summary of Video Editing Results</h2>
      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video0"  autoplay muted loop playsinline height="100%">
          <source src="static/videos/FreeMask.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>
  </div>
</div>
</div>
</section> -->


<!------------------------ Comparison Results ---------------------------->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2">Comparison Results</h2>
      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1"  class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/1_comparison_1.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1"  class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/2_comparison_2.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1"  class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/3_comparison_3.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>
  </div>
</div>
</div>
</section>
<!---------------------- End Comparison Results ------------------------>


<!------------------------    Ablation Results  ---------------------------->
<section class="section hero">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2"> Ablation Results</h2>
      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/4_ablation_1.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/5_ablation_2.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

  </div>
</div>
</div>
</section>
<!------------------------ End Ablation Results ---------------------------->



<!------------------------    Extensive Results  ---------------------------->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2"> Extensive Results</h2>
      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/6_extensive_1.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/7_extensive_2.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

      <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/8_extensive_3.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

            <div class="marquee-item-long">
        <video onloadstart="this.playbackRate = 0.75;" poster="" id="video1" class="lozad" autoplay muted loop playsinline height="100%">
          <source src="static/videos/9_extensive_4.mp4"
            type="video/mp4">
          sorry, your browser does not support HTML5 Videos.
          </video>
      </div>

  </div>
</div>
</div>
</section>
<!------------------------    End Extensive Results  ---------------------------->





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{cai2025freemask,
          title={FreeMask: Rethinking the Importance of Attention Masks for Zero-shot Video Editing},
          author={Cai, Lingling and Zhao, Kang and Yuan, Hangjie and Zhang, Yingya and Zhang, Shiwei and Huang, Kejie},
          booktitle={Proceedings of the Thirty-Ninth Conference on Association for the Advancement of Artificial Intelligence (AAAI-25)},
          year={2025}
        }
  </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- 
<section class="section">
  <div class="hero-body">
    <div class="container is-max-desktop content">
    <h2 class="title">Explanation</h2>
    <small>1. For better visualization, we only show the edited word in this page. Please check our paper and code for the whole source prompt. </small> <br/>
    <small>2. Most of the results are directly edited from <a href="https://github.com/vinthony/deep-blind-watermark-removal">Stable diffusion v1.4</a>. We use one-shot video diffusion model (<a href="https://tuneavideo.github.io/">Tune-A-Video</a>) checkpoints for shape-aware editing, whose results are marked as *. </small> <br/>
    <small>3. Our method does not require training a Tune-A-Video Model. </small>
    <h2 class="title">Acknowledgement</h2>
    <small>This project is supported by the National Key R&D Program of China under grant number 2022ZD0161501.
      The authors would also like to express sincere gratitude to Tencent AI Lab for providing the necessary computation resources and a conducive environment for research. 
       </small>
    </div>
  </section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/vinthony/project-page-template">modification version</a> of <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> from <a href="https://github.com/vinthony">vinthony</a>.
            You are free to borrow this website. We just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
